# Sharing Very Large Datasets

In the era of Big Data, research datasets can often be several hundreds of gigabytes, or even terabytes, in size. How do we share Very Large Datasets in ways that make it easy for both data contributors and data users?

## Suggested Meta-data to include

 - Description of the theoretical context and experimental paradigm
 - Description of experimental conditions, ideally a fully descriptive data collection protocol
   - date and time of data collection
   - researchers involved in data collection
   - species, age, sex, etc of experiment participants/subjects
   - housing conditions / home context of experiment participants/subjects
   - tools and techniques used to collect data (electrode type, video camera model, tissue staining technique, microphone type, etc)
   - surgical procedures involved, if any
   - if stimuli were used, how were the stimuli generated?
   - how timings of stimuli, recordings, and any other events in the experiment were correlated and/or synchronized
 - Known caveats about the use of the data (i.e. identified artifacts)
 - links to publications
 - tools and procedures used to process the data (see section on Data Provenance)
